{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzc6DWJmGEFU",
    "outputId": "b2d7fdde-d28c-4290-b33e-4af4f4553719"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "X55sBTYjBjL_",
    "outputId": "c03ac140-1a1a-4024-c0be-5b76416312da"
   },
   "outputs": [],
   "source": [
    "%pip install -q git+https://github.com/DeepTrackAI/deeplay.git\n",
    "# %pip install deeplay\n",
    "%pip install -q deeptrack --pre\n",
    "%pip install -q multiprocess\n",
    "\n",
    "import torch\n",
    "from rich import print\n",
    "\n",
    "# Define GPU device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\\nCUDA version: {torch.version.cuda}\\nDevice: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REpzVQylMDLQ"
   },
   "outputs": [],
   "source": [
    "!sudo apt install cm-super dvipng texlive-latex-extra texlive-latex-recommended texlive-fonts-extra texlive-science 2>/dev/null >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3sgQwSU1gj9"
   },
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import deeptrack as dt\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import multiprocess as mp\n",
    "from pathlib import Path\n",
    "import os\n",
    "from kornia.contrib import extract_tensor_patches, combine_tensor_patches\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from kornia.utils import tensor_to_image\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from contextlib import contextmanager\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pP5Om_7eMVXg"
   },
   "outputs": [],
   "source": [
    "PLOT_CONTEXT = {\n",
    "    ##########\n",
    "    # Figure #\n",
    "    ##########\n",
    "    \"figure.autolayout\": True,\n",
    "    \"figure.subplot.left\": 0.5,\n",
    "    \"figure.dpi\": 600,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.04,\n",
    "    # Linewidths\n",
    "    \"axes.linewidth\": 0.25,\n",
    "    \"grid.linewidth\": 0.25,\n",
    "    \"xtick.major.width\": 0.25,\n",
    "    \"xtick.minor.width\": 0.25,\n",
    "    \"ytick.major.width\": 0.25,\n",
    "    \"ytick.minor.width\": 0.25,\n",
    "    # Plots\n",
    "    \"lines.linewidth\": 0.5,\n",
    "    \"lines.markersize\": 2,\n",
    "    \"axes.grid\": False,\n",
    "    # Ticks\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"xtick.minor.visible\": True,\n",
    "    \"ytick.minor.visible\": True,\n",
    "    \"xtick.top\": True,\n",
    "    \"ytick.right\": True,\n",
    "    # Legend\n",
    "    \"patch.linewidth\": 0.25,\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.fancybox\": False,\n",
    "    \"legend.loc\": \"upper left\",\n",
    "    # Colours\n",
    "    \"axes.prop_cycle\": \"(cycler('color', ['k', 'r', 'b', 'g']) + cycler('ls', ['-', '--', ':', '-.']))\",\n",
    "    ###############\n",
    "    # Typesetting #\n",
    "    ###############\n",
    "    # Title\n",
    "    \"figure.titlesize\": 10,\n",
    "    \"figure.titleweight\": \"bold\",\n",
    "    \"axes.titlesize\": 9,\n",
    "    \"axes.titleweight\": \"normal\",\n",
    "    # Axes\n",
    "    \"axes.labelsize\": 9,\n",
    "    \"axes.labelweight\": \"normal\",\n",
    "    # Ticks\n",
    "    \"xtick.labelsize\": 7,\n",
    "    \"ytick.labelsize\": 7,\n",
    "    \"xtick.major.size\" : 3,\n",
    "    \"ytick.major.size\" : 3,\n",
    "    \"xtick.minor.size\" : 1.5,\n",
    "    \"ytick.minor.size\" : 1.5,\n",
    "    # Legend\n",
    "    \"legend.fontsize\": 6,\n",
    "    \"legend.edgecolor\": \"grey\",\n",
    "    #########\n",
    "    # LaTeX #\n",
    "    #########\n",
    "    \"text.usetex\": True,  # Use LaTeX\n",
    "    # LaTeX standard math and physics preamble with sans-serif font in math mode\n",
    "    \"text.latex.preamble\": r\"\"\"\n",
    "\\usepackage{amsmath}\n",
    "\\usepackage{amssymb}\n",
    "\\usepackage{mathtools}\n",
    "\\usepackage{bbm}\n",
    "\\usepackage{gensymb}\n",
    "\\usepackage[italicdiff]{physics}\n",
    "\\usepackage{icomma}\n",
    "\\usepackage{siunitx}\n",
    "\\sisetup{\n",
    "  detect-all,\n",
    "  locale=UK,% Set locale to UK\n",
    "  output-decimal-marker={,}, % Set comma as decimal separator\n",
    "  range-phrase=--, % Set range to use \"--\" instead of \" to \"\n",
    "  range-units=single, % Use only a single unit in a range\n",
    "  per-mode=reciprocal, % Alternatively set to \"symbol\"\n",
    "  sticky-per, % Only one \\per-command\n",
    "  bracket-unit-denominator=false, % No parenthesis\n",
    "  separate-uncertainty=true, % Separate uncertainty with \"+/-\"\n",
    "}\n",
    "\\usepackage{sansmath}\n",
    "\\sansmath\n",
    "\\centering\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "mpl.rcParams.update(PLOT_CONTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_fVbgKMCoeE",
    "outputId": "3ce311d1-37b8-41c4-cf14-62a62f223edf"
   },
   "outputs": [],
   "source": [
    "DATA_PATH: Path = Path.cwd() / \"data\"\n",
    "DATA_PATH.mkdir(exist_ok=True)\n",
    "os.environ[\"DATA_PATH\"] = str(DATA_PATH)\n",
    "\n",
    "mnist_dataset_path: Path = DATA_PATH / \"MNIST_dataset\" / \"mnist\"\n",
    "\n",
    "if not mnist_dataset_path.exists():\n",
    "    !cd $DATA_PATH && git clone https://github.com/DeepTrackAI/MNIST_dataset\n",
    "\n",
    "train_files = dt.sources.ImageFolder(\n",
    "    root=str(mnist_dataset_path / \"train\"),\n",
    ")\n",
    "test_files = dt.sources.ImageFolder(\n",
    "    root=str(mnist_dataset_path / \"test\"),\n",
    ")\n",
    "files = dt.sources.Join(train_files, test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lp3pD_r4WxoH"
   },
   "outputs": [],
   "source": [
    "image_pipeline = (\n",
    "    dt.LoadImage(files.path)\n",
    "    >> dt.NormalizeMinMax()\n",
    "    >> dt.MoveAxis(2, 0)\n",
    "    >> dt.pytorch.ToTensor(dtype=torch.float)\n",
    ")\n",
    "\n",
    "label_pipeline = (\n",
    "    dt.Value(files.label_name[0])\n",
    "    >> int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqG8AgTpXJbF"
   },
   "outputs": [],
   "source": [
    "train_dataset = dt.pytorch.Dataset(image_pipeline & label_pipeline,\n",
    "                                  inputs=train_files)\n",
    "test_dataset = dt.pytorch.Dataset(image_pipeline & label_pipeline,\n",
    "                                  inputs=test_files)\n",
    "\n",
    "n_dataset_workers = mp.cpu_count()\n",
    "train_loader = dl.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=n_dataset_workers)\n",
    "test_loader = dl.DataLoader(test_dataset, batch_size=64, shuffle=True,num_workers=n_dataset_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyYtvQzDEuK9"
   },
   "outputs": [],
   "source": [
    "class Generator(dl.UNet2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.patch_size = kwargs[\"channels\"][0]\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # self[..., \"activation\"].configure(nn.GELU)\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, _, height, width = input.shape\n",
    "        input.requires_grad_()\n",
    "\n",
    "        if any(l < self.patch_size for l in (height, width)):\n",
    "            raise ValueError(\n",
    "                f\"Image ({height}x{width}) is smaller than kernel size ({self.patch_size}x{self.patch_size})\"\n",
    "            )\n",
    "\n",
    "        stride = [np.gcd(height, self.patch_size), np.gcd(width, self.patch_size)]\n",
    "        input_patches = extract_tensor_patches(input=input, window_size=self.patch_size, stride=stride).movedim(1, 0)\n",
    "\n",
    "        output_patches = torch.vmap(super().forward)(input_patches).movedim(0, 1)\n",
    "\n",
    "        output = combine_tensor_patches(\n",
    "            patches=output_patches, original_size=(height, width), window_size=self.patch_size, stride=stride\n",
    "        )\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "generator_model = Generator(\n",
    "    in_channels=1,\n",
    "    channels=[16, 32, 64],\n",
    "    out_channels=1,\n",
    "    skip=dl.Cat()\n",
    ")\n",
    "# print(generator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5k2PFlRUFRvM"
   },
   "outputs": [],
   "source": [
    "class Discriminator(dl.DeeplayModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            hidden_channels_cnn,\n",
    "            hidden_channels_mlp,\n",
    "            out_channels_cnn,\n",
    "            out_features\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = dl.ConvolutionalNeuralNetwork(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels_cnn,\n",
    "            out_channels=out_channels_cnn,\n",
    "            pool=nn.MaxPool2d(kernel_size=2),\n",
    "            out_activation=nn.ReLU,\n",
    "        )\n",
    "\n",
    "        self.pool = dl.Layer(nn.MaxPool2d, kernel_size=2)\n",
    "        self.flatten = dl.Layer(nn.Flatten)\n",
    "\n",
    "        self.dense = dl.MultiLayerPerceptron(\n",
    "            in_features=out_channels_cnn,\n",
    "            hidden_features=hidden_channels_mlp,\n",
    "            out_features=out_features,\n",
    "            out_activation=nn.Identity,\n",
    "        )\n",
    "        self.dense[..., \"layer#0\"].configure(nn.LazyLinear)\n",
    "        # self.dense[..., \"activation#-1\"] = dl.Layer[nn.Softmax]\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.flatten(self.pool(x))\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "discriminator_1 = Discriminator(\n",
    "    in_channels=1,\n",
    "    hidden_channels_cnn=[16, 32, 64],\n",
    "    hidden_channels_mlp=[64, 32],\n",
    "    out_channels_cnn=64,\n",
    "    out_features=1\n",
    ")\n",
    "discriminator_2 = Discriminator(\n",
    "    in_channels=1,\n",
    "    hidden_channels_cnn=[16, 32, 64],\n",
    "    hidden_channels_mlp=[64, 32],\n",
    "    out_channels_cnn=64,\n",
    "    out_features=10\n",
    ")\n",
    "# discriminator_2.dense[..., \"activation#-1\"] = dl.Layer[nn.Softmax]\n",
    "# print(discriminator_1)\n",
    "# print(discriminator_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "k5UrmWExUjjv",
    "outputId": "ddced869-a6ac-4a8a-db04-2bd2c5cf5a57"
   },
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "class GAN(dl.Application):\n",
    "    def __init__(self, generator, discriminator_1=None, discriminator_2=None, plot_outputs=False, disc_1_loss_w=1, disc_2_loss_w=1, norm_loss_w=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Neural networks\n",
    "        self.generator = generator\n",
    "        self.discriminator_1 = discriminator_1\n",
    "        self.discriminator_2 = discriminator_2\n",
    "\n",
    "        if not discriminator_1 and not discriminator_2:\n",
    "            raise ValueError(\"The GAN must have at least one discriminator\")\n",
    "\n",
    "        # Plot outputs for first batch in every epoch\n",
    "        self.plot_outputs = plot_outputs\n",
    "\n",
    "        # Generator loss weights\n",
    "        self.disc_1_loss_w = disc_1_loss_w\n",
    "        self.disc_2_loss_w = disc_2_loss_w\n",
    "        self.norm_loss_w = norm_loss_w\n",
    "\n",
    "        self.ssim = StructuralSimilarityIndexMeasure()\n",
    "\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizers, schedulers = [], []\n",
    "\n",
    "        generator_optimizer = self.create_optimizer_with_params(\n",
    "            dl.Adam(lr=1e-4,betas=(0.5, 0.999)), self.generator.parameters()\n",
    "        )\n",
    "        optimizers.append(generator_optimizer)\n",
    "\n",
    "        if self.discriminator_1:\n",
    "            discriminator_1_optimizer = self.create_optimizer_with_params(\n",
    "                dl.Adam(lr=1e-5), self.discriminator_1.parameters()\n",
    "            )\n",
    "            optimizers.append(discriminator_1_optimizer)\n",
    "            discriminator_1_scheduler = StepLR(discriminator_1_optimizer, step_size=1,gamma=0.8)\n",
    "            schedulers.append(discriminator_1_scheduler)\n",
    "\n",
    "        if self.discriminator_2:\n",
    "            discriminator_2_optimizer = self.create_optimizer_with_params(\n",
    "                dl.Adam(lr=1e-4), self.discriminator_2.parameters()\n",
    "            )\n",
    "            optimizers.append(discriminator_2_optimizer)\n",
    "\n",
    "        return optimizers, schedulers\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.generator(batch)\n",
    "\n",
    "    def plot_training_images(self, batch_tensor, n_plots, name=None):\n",
    "        fig, axs = plt.subplots(1, n_plots, figsize=((10, n_plots * 10)))\n",
    "\n",
    "        for i_ax, ax, img in zip(range(n_plots), axs.ravel(), [tensor_to_image(o) for o in batch_tensor[:n_plots].clone().detach()]):\n",
    "            ax.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "            if name and i_ax == 0:\n",
    "                ax.set_ylabel(name)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "            else:\n",
    "                ax.set_axis_off()\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def generator_discriminator_1_loss(self, input, target):\n",
    "        return self.disc_1_loss_w * F.binary_cross_entropy_with_logits(input, target)\n",
    "\n",
    "    def generator_norm_loss(self, input, target):\n",
    "        return self.norm_loss_w * F.binary_cross_entropy_with_logits(input, target)\n",
    "\n",
    "    def generator_discriminator_2_loss(self, input, target):\n",
    "        # Prepare target\n",
    "        target_oh = F.one_hot(target, num_classes=10)\n",
    "        fake_target = torch.zeros_like(input)\n",
    "\n",
    "        formatted_input = F.softmax(input, dim=1) * target_oh.squeeze(1)\n",
    "\n",
    "        return self.disc_2_loss_w * torch.sum((formatted_input - fake_target) ** 2.0) / fake_target.shape[0]\n",
    "\n",
    "    def discriminator_1_loss(self, output_real, output_fake, target_real, target_fake):\n",
    "        loss_real = F.binary_cross_entropy_with_logits(output_real, target_real)\n",
    "        loss_fake = F.binary_cross_entropy_with_logits(output_fake, target_fake)\n",
    "\n",
    "        return (loss_real + loss_fake) / 2\n",
    "\n",
    "    def discriminator_2_loss(self, input, target):\n",
    "        return F.binary_cross_entropy(input, target)\n",
    "\n",
    "    def train_generator(self, optimizer, input, target, batch_idx):\n",
    "        self.toggle_optimizer(optimizer)\n",
    "\n",
    "        fake_label = torch.zeros(input.size(0), 1).type_as(input)\n",
    "\n",
    "        # Feed input into generator\n",
    "        gen_output = self(input)\n",
    "\n",
    "        if self.discriminator_1:\n",
    "            # Feed generated image to discriminator 1\n",
    "            disc_1_output_fake = self.discriminator_1(gen_output)\n",
    "\n",
    "            # Prepare target\n",
    "            real_label = torch.ones(input.size(0), 1).type_as(input)\n",
    "\n",
    "            # Compute loss\n",
    "            gen_loss_disc_1 = self.generator_discriminator_1_loss(disc_1_output_fake, real_label)\n",
    "            self.log(\"train_gen_loss_disc_1_step\", gen_loss_disc_1, prog_bar=True)\n",
    "            self.log(\"train_gen_loss_disc_1_epoch\", gen_loss_disc_1, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        else:\n",
    "            gen_loss_disc_1 = 0\n",
    "\n",
    "        if self.discriminator_2:\n",
    "            # Feed generated image to discriminator 2\n",
    "            disc_2_output_fake = self.discriminator_2(gen_output)\n",
    "\n",
    "            # Compute loss\n",
    "            gen_loss_disc_2 = self.generator_discriminator_2_loss(disc_2_output_fake, target)\n",
    "            self.log(\"train_gen_loss_disc_2_step\", gen_loss_disc_2, prog_bar=True)\n",
    "            self.log(\"train_gen_loss_disc_2_epoch\", gen_loss_disc_2, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        else:\n",
    "            gen_loss_disc_2 = 0\n",
    "\n",
    "        # Compute norm of pixel difference between input and generator output\n",
    "        diff = input - gen_output\n",
    "        norm = torch.norm(diff, dim=(2,3))\n",
    "\n",
    "        # Compute loss for norm\n",
    "        gen_loss_norm = self.generator_norm_loss(norm, fake_label)\n",
    "        self.log(\"train_gen_loss_norm_step\", gen_loss_norm, prog_bar=True)\n",
    "        self.log(\"train_gen_loss_norm_epoch\", gen_loss_norm, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        # Compute total generator loss\n",
    "        gen_loss = gen_loss_disc_2 + gen_loss_disc_1 + gen_loss_norm\n",
    "        self.log(\"train_gen_loss_step\", gen_loss, prog_bar=True)\n",
    "        self.log(\"train_gen_loss_epoch\", gen_loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        # Run optimization\n",
    "        self.manual_backward(gen_loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        self.untoggle_optimizer(optimizer)\n",
    "\n",
    "        ###############################\n",
    "        # Print output once per epoch #\n",
    "        ###############################\n",
    "\n",
    "        if batch_idx == 0 and self.plot_outputs:\n",
    "            print(f\"[bold]Epoch {self.current_epoch}\")\n",
    "            n_plots = 5\n",
    "\n",
    "            self.plot_training_images(input, n_plots, \"Input image\")\n",
    "            self.plot_training_images(gen_output, n_plots, \"Generator output\")\n",
    "            self.plot_training_images(torch.abs(diff), n_plots, \"Absolute difference\")\n",
    "\n",
    "            if self.discriminator_1:\n",
    "                print(\"Discriminator 1 guess\\n\", disc_1_output_fake[:5].transpose(0,1))\n",
    "\n",
    "            if self.discriminator_2:\n",
    "                print(\"Discriminator 2 guess (fake)\\n\", torch.argmax(disc_2_output_fake,dim=1)[:5].unsqueeze(-1).transpose(0,1))\n",
    "\n",
    "    def train_discriminator_1(self, optimizer, input, output):\n",
    "        self.toggle_optimizer(optimizer)\n",
    "\n",
    "        # Feed input into generator\n",
    "        gen_output = self(input)\n",
    "\n",
    "        # Feed real input and generator output into discriminator 1\n",
    "        disc_1_output_real = self.discriminator_1(input)\n",
    "        disc_1_output_fake = self.discriminator_1(gen_output)\n",
    "\n",
    "        real_label = torch.ones(input.size(0), 1).type_as(input)\n",
    "        fake_label = torch.zeros(input.size(0), 1).type_as(input)\n",
    "\n",
    "        # Compute loss\n",
    "        disc_1_loss = self.discriminator_1_loss(disc_1_output_real, disc_1_output_fake, real_label, fake_label)\n",
    "        self.log(\"train_disc_1_loss_step\", disc_1_loss, prog_bar=True)\n",
    "        self.log(\"train_disc_1_loss_epoch\", disc_1_loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        # Run optimization\n",
    "        self.manual_backward(disc_1_loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        self.untoggle_optimizer(optimizer)\n",
    "\n",
    "    def train_discriminator_2(self, optimizer, input, target, batch_idx):\n",
    "        self.toggle_optimizer(optimizer)\n",
    "\n",
    "        # Feed input into discriminator directly (only train on real images)\n",
    "        disc_2_output_real = self.discriminator_2(input)\n",
    "\n",
    "        # Compute loss\n",
    "        disc_2_loss = F.cross_entropy(disc_2_output_real, target.squeeze())\n",
    "        self.log(\"train_disc_2_loss_step\", disc_2_loss, prog_bar=True)\n",
    "        self.log(\"train_disc_2_loss_epoch\", disc_2_loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        # Run optimization\n",
    "        self.manual_backward(disc_2_loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        self.untoggle_optimizer(optimizer)\n",
    "\n",
    "        # Print discriminator 2 guess at start of epoch\n",
    "        if batch_idx == 0 and self.plot_outputs:\n",
    "            print(\"Discriminator 2 guess (real)\\n\", torch.argmax(disc_2_output_real[:5],dim=1))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        ####################\n",
    "        # Prepare training #\n",
    "        ####################\n",
    "\n",
    "        self.train()\n",
    "\n",
    "        # Prepare inputs and targets\n",
    "        input, target = batch\n",
    "\n",
    "        # Get optimizers\n",
    "        optimizers = self.optimizers()\n",
    "        gen_opt = optimizers[0]\n",
    "\n",
    "        if self.discriminator_1 and self.discriminator_2:\n",
    "            disc_1_opt = optimizers[1]\n",
    "            disc_1_sched = self.lr_schedulers()\n",
    "            disc_2_opt = optimizers[2]\n",
    "        elif self.discriminator_1 and not self.discriminator_2:\n",
    "            disc_1_opt = optimizers[1]\n",
    "            disc_1_sched = self.lr_schedulers()\n",
    "        else:\n",
    "            disc_2_opt = optimizers[1]\n",
    "\n",
    "        # Train generator\n",
    "        self.train_generator(gen_opt, input, target, batch_idx)\n",
    "\n",
    "        # Train discriminator 1\n",
    "        if self.discriminator_1:\n",
    "            self.train_discriminator_1(disc_1_opt, input, target)\n",
    "\n",
    "        # Train discriminator 2\n",
    "        if self.discriminator_2:\n",
    "            self.train_discriminator_2(disc_2_opt, input, target, batch_idx)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        metrics = {}\n",
    "\n",
    "        # Prepare inputs and targets\n",
    "        input, target = batch\n",
    "\n",
    "        # Feed input into generator\n",
    "        gen_output = self(input)\n",
    "\n",
    "        # Compute structural similarity index\n",
    "        metrics[\"test_ssim\"] = self.ssim(gen_output, input)\n",
    "\n",
    "        if self.discriminator_1:\n",
    "            # Feed real input and generator output into discriminator 1\n",
    "            disc_1_output_real = self.discriminator_1(input)\n",
    "            disc_1_output_fake = self.discriminator_1(gen_output)\n",
    "\n",
    "            real_label = torch.ones(input.size(0), 1).type_as(input)\n",
    "            fake_label = torch.zeros(input.size(0), 1).type_as(input)\n",
    "\n",
    "            # Compute accuracies\n",
    "            metrics[\"test_accuracy_discriminator_1_real\"] = accuracy(torch.round(disc_1_output_real), real_label, task=\"binary\")\n",
    "            metrics[\"test_accuracy_discriminator_1_fake\"] = accuracy(torch.round(disc_1_output_fake), fake_label, task=\"binary\")\n",
    "            metrics[\"test_accuracy_discriminator_1_total\"] = accuracy(torch.round(torch.cat((disc_1_output_real, disc_1_output_fake), dim=0)), torch.cat((real_label, fake_label), dim=0), task=\"binary\")\n",
    "\n",
    "        if self.discriminator_2:\n",
    "            disc_2_output_real = self.discriminator_2(input)\n",
    "            disc_2_output_fake = self.discriminator_2(gen_output)\n",
    "\n",
    "            # Compute accuracy\n",
    "            metrics[\"test_accuracy_discriminator_2_real\"] = accuracy(torch.argmax(disc_2_output_real,dim=1).unsqueeze(-1), target, task=\"multiclass\", num_classes=10)\n",
    "            metrics[\"test_accuracy_discriminator_2_fake\"] = accuracy(torch.argmax(disc_2_output_fake,dim=1).unsqueeze(-1), target, task=\"multiclass\", num_classes=10)\n",
    "\n",
    "        self.log_dict(metrics)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "\n",
    "gan = GAN(\n",
    "    generator=generator_model.create(),\n",
    "    discriminator_1=discriminator_1.create(),\n",
    "    discriminator_2=discriminator_2.create(),\n",
    "    disc_1_loss_w=2,\n",
    "    disc_2_loss_w=100,\n",
    "    norm_loss_w=0.5,\n",
    "    plot_outputs=True\n",
    ")\n",
    "print(gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Lngz24puhlcp",
    "outputId": "80c7b25e-1aec-4a87-95a4-3d272fe1188e"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "print(\"[bold]Generator\")\n",
    "summary(gan.generator, (1, 28, 28), device=\"cpu\")\n",
    "print(\"[bold]Discriminator 1\")\n",
    "summary(gan.discriminator_1, (1, 28, 28), device=\"cpu\")\n",
    "print(\"[bold]Discriminator 2\")\n",
    "summary(gan.discriminator_2, (1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0df6561b871943b9b14d8b2f87a9889d",
      "c3197e131dc44d10ad3584bb65560883"
     ]
    },
    "id": "6H77IL_2YA2P",
    "outputId": "a65777f8-b92d-418e-8f12-fae2173667b1"
   },
   "outputs": [],
   "source": [
    "from deeplay.callbacks import LogHistory\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "mpl.rcParams.update({\"figure.dpi\":100})\n",
    "\n",
    "logger = CSVLogger(save_dir=RESULTS_DIR, name=f\"gan_full_logs\")\n",
    "training_history = LogHistory()\n",
    "trainer = dl.Trainer(max_epochs=100, callbacks=[training_history], logger=logger)\n",
    "trainer.fit(gan, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n-GvwqBj5tW7",
    "outputId": "06a47146-5b71-494e-f550-c00c2c1ac606"
   },
   "outputs": [],
   "source": [
    "training_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "266739abb24c4866aaeeb73b74be6dfb",
      "c65f85ce62e34b8596d38921bb09d3b4"
     ]
    },
    "id": "hHAsWJ2NFwT5",
    "outputId": "ebf867c4-66a7-4a8c-daf5-ba23649cd63b"
   },
   "outputs": [],
   "source": [
    "trainer.test(gan, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IX9rapFkFhO0"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update({\"figure.dpi\":600})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "l3qlBunRdHCP",
    "outputId": "6e610cbe-a648-42c3-f3a3-adaffe34c0b9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "EXPERIMENT_1_DIR = Path(\"gan_experiment_1\")\n",
    "EXPERIMENT_1_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "def run_gan_experiment_discriminator_1():\n",
    "    n_epochs = 50\n",
    "    n_runs = 10\n",
    "    norm_loss_w = 1\n",
    "    disc_1_norm_loss_w_ratio_arr = np.geomspace(1e-2, 1e2, n_runs)\n",
    "    disc_1_loss_w_arr = disc_1_norm_loss_w_ratio_arr\n",
    "    sum_arr = disc_1_loss_w_arr + norm_loss_w\n",
    "    disc_1_loss_w_arr /= sum\n",
    "    norm_loss_w /= sum\n",
    "\n",
    "    test_metrics_dcts = []\n",
    "\n",
    "    for i_run, disc_1_loss_w, disc_1_norm_loss_w_ratio in zip(range(len(disc_1_loss_w_arr)), disc_1_loss_w_arr, disc_1_norm_loss_w_ratio_arr):\n",
    "        gan = GAN(\n",
    "            generator=generator_model.create(),\n",
    "            discriminator_1=discriminator_1.create(),\n",
    "            disc_1_loss_w=disc_1_loss_w,\n",
    "            norm_loss_w=norm_loss_w\n",
    "        )\n",
    "\n",
    "        logger = CSVLogger(save_dir=EXPERIMENT_1_DIR, name=f\"gan_disc_1_{i_run}_{disc_1_loss_w}_logs\")\n",
    "        trainer = dl.Trainer(max_epochs=n_epochs, logger=logger)\n",
    "        trainer.fit(gan, train_loader)\n",
    "        torch.save(gan.state_dict(),  EXPERIMENT_1_DIR / f\"gan_disc_1_{i_run}_{disc_1_loss_w}.pth\")\n",
    "\n",
    "        test_metrics = trainer.test(gan, test_loader)[0]\n",
    "        test_metrics[\"disc_1_loss_w\"] = disc_1_loss_w\n",
    "        test_metrics[\"norm_loss_w\"] = norm_loss_w\n",
    "        test_metrics[\"disc_1_norm_loss_w_ratio\"] = disc_1_norm_loss_w_ratio\n",
    "        test_metrics[\"epochs\"] = n_epochs\n",
    "\n",
    "        test_metrics_dcts.append(test_metrics)\n",
    "\n",
    "    return pd.DataFrame(test_metrics_dcts)\n",
    "\n",
    "\n",
    "\n",
    "experiment_1_metrics_df = run_gan_experiment_discriminator_1()\n",
    "experiment_1_metrics_df.to_csv(EXPERIMENT_1_DIR / \"test_metrics.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6ahBa_4O_9x"
   },
   "outputs": [],
   "source": [
    "os.environ[\"EXPERIMENT_1_DIR\"] = str(EXPERIMENT_1_DIR)\n",
    "os.environ[\"EXPERIMENT_1_ZIP_FILE\"] = \"gan_experiment_1.zip\"\n",
    "!zip -r ${EXPERIMENT_1_ZIP_FILE} ${EXPERIMENT_1_DIR}\n",
    "!cp -r ${EXPERIMENT_1_ZIP_FILE} /content/drive/MyDrive/${EXPERIMENT_1_ZIP_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "vUMcM1U_Idqd",
    "outputId": "83d26f95-110f-4b56-a875-ddd312f8fc70"
   },
   "outputs": [],
   "source": [
    "experiment_1_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntUr28BDjkKe"
   },
   "source": [
    "## Warp images for model architecture graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gN47J3CzqnNl"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import kornia as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWOEpHD9qe7F"
   },
   "outputs": [],
   "source": [
    "WARPED_IMAGES_DIR = Path(\"warped_images\")\n",
    "WARPED_IMAGES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def warp_image(image, height_factor, width_factor, scaling_factor):\n",
    "    # Rezise image for warping, but keep image pixelated\n",
    "    image = cv2.resize(image, tuple(np.array(image.shape[:2])*scaling_factor), interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "    height,width = image.shape\n",
    "    height_max = height-1\n",
    "    width_max = width -1\n",
    "    height_factor = 0.9\n",
    "    width_factor = 0.5\n",
    "    new_height = int(height * height_factor)\n",
    "    new_width = int(width * width_factor)\n",
    "    height_diff = height - new_height\n",
    "    width_diff = width - new_width\n",
    "\n",
    "    # Change image formate to introduce transparency\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGRA)*255\n",
    "\n",
    "    # Define warp points (old and new positions)\n",
    "    points_1 = np.float32([[0,0],[0,height_max],[width_max,0],[width_max,height_max]])\n",
    "    points_2 = np.float32([[0,height_diff],[0,height_max],[width_max-width_diff,0],[width_max-width_diff,height_max-height_diff]])\n",
    "\n",
    "    # Compute transformation matrix\n",
    "    transform_mat = cv2.getPerspectiveTransform(points_1,points_2)\n",
    "\n",
    "    # Perform warping\n",
    "    dst = cv2.warpPerspective(image,transform_mat,(width, height))\n",
    "\n",
    "    # Crop warped image\n",
    "    dst = dst[:,:new_width]\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "def generate_plot_warped_images(gan, n_images):\n",
    "    height_factor = 0.9\n",
    "    width_factor = 0.6\n",
    "    scaling_factor = 20\n",
    "\n",
    "    for i_batch, batch in enumerate(test_loader):\n",
    "        input, target = batch\n",
    "        gen_output = gan.generator(input[:n_images])\n",
    "\n",
    "        for i_plot in range(n_images):\n",
    "            input_image = tensor_to_image(input[i_plot])\n",
    "            gen_image = tensor_to_image(gen_output[i_plot])\n",
    "\n",
    "            warped_input_image = warp_image(input_image, height_factor, width_factor, scaling_factor)\n",
    "            warped_gen_image = warp_image(gen_image, height_factor, width_factor, scaling_factor)\n",
    "\n",
    "            input_image_resized = cv2.resize(input_image, tuple(np.array(input_image.shape[:2])*scaling_factor), interpolation = cv2.INTER_NEAREST)\n",
    "            gen_image_resized =cv2.resize(gen_image, tuple(np.array(gen_image.shape[:2])*scaling_factor), interpolation = cv2.INTER_NEAREST)\n",
    "            cv2.imwrite(str(WARPED_IMAGES_DIR/f\"mnist_{i_plot}_digit_{target[i_plot].item()}.png\"), input_image_resized*255)\n",
    "            cv2.imwrite(str(WARPED_IMAGES_DIR/f\"gen_mnist_{i_plot}_digit_{target[i_plot].item()}.png\"), gen_image_resized*255)\n",
    "            cv2.imwrite(str(WARPED_IMAGES_DIR/f\"warped_mnist_{i_plot}_digit_{target[i_plot].item()}.png\"), warped_input_image)\n",
    "            cv2.imwrite(str(WARPED_IMAGES_DIR/f\"warped_gen_mnist_{i_plot}_digit_{target[i_plot].item()}.png\"), warped_gen_image)\n",
    "\n",
    "        break\n",
    "\n",
    "generate_plot_warped_images(gan, n_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RumZ0GAH4xl_",
    "outputId": "a0decc0d-3fea-4ef1-d719-1628e24e5de7"
   },
   "outputs": [],
   "source": [
    "def generate_plot_generated_images(gan, n_plots):\n",
    "    for i_batch, batch in enumerate(test_loader):\n",
    "        input, _ = batch\n",
    "        input = input[:n_plots]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gen_output = gan.generator(input.to(device)).cpu()\n",
    "\n",
    "        abs_diff = torch.abs(input - gen_output)\n",
    "        break\n",
    "\n",
    "    fig, axs = plt.subplots(n_plots, 3, figsize=((3, n_plots)))\n",
    "\n",
    "    for i_row, row_axs in enumerate(axs):\n",
    "        row_axs[0].imshow(tensor_to_image(input[i_row]), cmap=\"gray\")\n",
    "        row_axs[0].set_xlabel(r\"$\\downarrow$\\\\9\")\n",
    "        row_axs[1].imshow(tensor_to_image(gen_output[i_row]), cmap=\"gray\")\n",
    "        row_axs[2].imshow(tensor_to_image(abs_diff[i_row]), cmap=\"gray\")\n",
    "\n",
    "        [(ax.set_xticks([]), ax.set_yticks([])) for ax in row_axs]\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# gan = GAN(\n",
    "#     generator=generator_model.create(),\n",
    "#     discriminator_1=discriminator_1.create()\n",
    "# ).to(device)\n",
    "# gan.load_state_dict(torch.load(EXPERIMENT_1_DIR / \"gan_experiment_discriminator_1_1_50.0.pth\"))\n",
    "plot = generate_plot_generated_images(gan, 3)\n",
    "# plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzBj4StFK-s1"
   },
   "outputs": [],
   "source": [
    "torch.save(gan.state_dict(),  \"nice_gan_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_64Er7gYuJ4",
    "outputId": "e6593a65-120c-4f3f-ece3-c757044a2ae9"
   },
   "outputs": [],
   "source": [
    "gan.load_state_dict(torch.load(\"/content/drive/MyDrive/data/results/nice_gan_full.pth\"))\n",
    "gan.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOhcNHfTZVjq",
    "outputId": "df19c468-c133-4c18-f27f-c0e1d392b737"
   },
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(generate_image=False):\n",
    "    # Initialize lists to store predictions and ground truth labels\n",
    "    predicted_labels = []\n",
    "    ground_truth_labels = []\n",
    "\n",
    "    # Iterate through the test loader\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        if generate_image:\n",
    "            # Pass the images through the generator to generate fake images\n",
    "            generated_images = gan.generator(images.to(device)).cpu()\n",
    "        else:\n",
    "            generated_images = images\n",
    "\n",
    "        # Pass generated images through discriminator 2 to get predictions\n",
    "        disc_2_output_fake = F.softmax(gan.discriminator_2(generated_images.to(device)).cpu(), dim=1)\n",
    "        batch_predicted_labels = torch.argmax(disc_2_output_fake, dim=1)\n",
    "\n",
    "        # Append batch predictions and ground truth labels to the lists\n",
    "        predicted_labels.extend(batch_predicted_labels.tolist())\n",
    "        ground_truth_labels.extend(labels.tolist())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    ground_truth_labels = np.array(ground_truth_labels).flatten()\n",
    "\n",
    "    conf_matrix = confusion_matrix(ground_truth_labels, predicted_labels, normalize=\"true\")*100\n",
    "    class_labels = sorted(set(ground_truth_labels))\n",
    "\n",
    "    return conf_matrix, class_labels\n",
    "\n",
    "conf_matrix, class_labels = compute_confusion_matrix(generate_image=False)\n",
    "conf_matrix_gen, class_labels_gen = compute_confusion_matrix(generate_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l3Dcv4USOSTw",
    "outputId": "f469df61-be12-48d7-81bd-c783f7ddac4d"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix, class_labels, plot_name):\n",
    "    # Plot confusion matrix using seaborn's heatmap\n",
    "    cm = 1/2.54  # centimeters in inches\n",
    "    plt.figure(figsize=(7*cm, 7*cm))\n",
    "    # Remove cbar ticks (using cbar_kwargs)\n",
    "    sns.heatmap(conf_matrix, annot=True, annot_kws=dict(fontsize=5), fmt=\".2g\",cmap=\"Reds\", xticklabels=class_labels, yticklabels=class_labels, vmin=0, vmax=100, cbar_kws=dict(label=\"Accuracy $[\\%]$\"))\n",
    "    plt.ylabel(\"Actual Class\")\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.tick_params(which=\"both\",width=0)\n",
    "    plt.savefig(f\"plot_{plot_name}.png\")\n",
    "\n",
    "plot_confusion_matrix(conf_matrix, class_labels,\"confusion_matrix_mnist\")\n",
    "plot_confusion_matrix(conf_matrix_gen, class_labels_gen,\"confusion_matrix_generated_mnist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXFnD_ivvtS9"
   },
   "outputs": [],
   "source": [
    "def generate_gaussian_noise(input_images, alpha):\n",
    "    # Generate random Gaussian noise with the same size as the input image\n",
    "    mean=0\n",
    "    std=0.1\n",
    "    noise = torch.randn_like(input_images) * std + mean\n",
    "    scaled_alpha = alpha / torch.norm(noise, dim = (2,3))\n",
    "    scaler = torch.ones_like(input_images) * scaled_alpha.unsqueeze(1).unsqueeze(2)\n",
    "    noise = noise * scaler* 3  #added factor of 3 to increase noise.\n",
    "\n",
    "    noisy_images = input_images + noise\n",
    "\n",
    "    # Clip the pixel values to ensure they're within the valid range [0, 1]\n",
    "    noisy_images = torch.clamp(noisy_images, 0, 1)\n",
    "\n",
    "    return noisy_images\n",
    "\n",
    "def generate_images(input_images):\n",
    "    with torch.no_grad():\n",
    "        gen_output = gan.generator(input_images.to(device)).cpu()\n",
    "\n",
    "    return gen_output\n",
    "\n",
    "\n",
    "def classify_images(images):\n",
    "    # Test discriminator 2 accuracy on images with gaussian noise\n",
    "    with torch.no_grad():\n",
    "        discriminator_2_output = gan.discriminator_2(images.to(device)).cpu()\n",
    "\n",
    "    return discriminator_2_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kdHvWrFjPcK2",
    "outputId": "e058f81b-4c70-452c-83ec-daa9b4eaa380"
   },
   "outputs": [],
   "source": [
    "#IMPLEMENT\n",
    "def other_classify_images(images):\n",
    "  # Test Other discriminator accuracy on images with gaussian noise\n",
    "  other_discriminator = gan.other_discriminator\n",
    "  with torch.no_grad():\n",
    "    other_discriminator_output = other_discriminator(images)\n",
    "  return other_discriminator_output\n",
    "\n",
    "\n",
    "def plot_images(batch_tensor, n_plots, plot_name, classifications=None, name=None):\n",
    "    fig, axs = plt.subplots(1, n_plots, figsize=((6*2, n_plots * 6)))\n",
    "\n",
    "    for i_ax, ax, img in zip(range(n_plots), axs.ravel(), [tensor_to_image(o) for o in batch_tensor[:n_plots].clone().detach()]):\n",
    "        ax.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "        if name and i_ax == 0:\n",
    "            ax.set_ylabel(name)\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # else:\n",
    "        #     ax.set_axis_off()\n",
    "\n",
    "        if classifications is not None:\n",
    "            ax.set_xlabel(r\"\\huge$\\downarrow$\\\\\\vspace{2mm}\\textbf{\" + str(classifications[i_ax].item()) + \"}\")\n",
    "\n",
    "    plt.savefig(f\"plot_{plot_name}.png\")\n",
    "\n",
    "\n",
    "input_images_matches = 0\n",
    "generated_images_matches = 0\n",
    "noisy_images_matches = 0\n",
    "\n",
    "for i_batch, batch in enumerate(test_loader):\n",
    "    input_images = batch[0]\n",
    "    gen_images = generate_images(input_images)\n",
    "    labels = batch[1].squeeze()\n",
    "\n",
    "    gen_diff = input_images - gen_images\n",
    "    gen_norm = torch.norm(gen_diff, dim=(2,3))\n",
    "    alpha = gen_norm\n",
    "\n",
    "    noisy_images = generate_gaussian_noise(input_images, alpha = alpha)\n",
    "    gaussian_diff = input_images - noisy_images\n",
    "    gaussian_norm = torch.norm(gaussian_diff, dim=(2,3))\n",
    "\n",
    "    classified_input_images = torch.argmax(classify_images(input_images),dim=1)\n",
    "    classified_generated_images = torch.argmax(classify_images(gen_images),dim=1)\n",
    "    classified_noisy_images = torch.argmax(classify_images(noisy_images),dim=1)\n",
    "\n",
    "    input_images_matches += torch.sum(labels == classified_input_images)\n",
    "    generated_images_matches += torch.sum(labels == classified_generated_images.unsqueeze(-1).transpose(0,1))\n",
    "    noisy_images_matches += torch.sum(labels == classified_noisy_images.unsqueeze(-1).transpose(0,1))\n",
    "\n",
    "\n",
    "    # print('gen norm', gen_norm[:5])\n",
    "    # print('gaussian', gaussian_norm[:5])\n",
    "    if i_batch == 0:\n",
    "      # Visualize the first few images\n",
    "      n_plots = 5\n",
    "      plot_images(input_images, n_plots, \"mnist_input\", classified_input_images)\n",
    "      plot_images(noisy_images, n_plots, \"mnist_noisy\", classified_noisy_images)\n",
    "      plot_images(torch.abs(gaussian_diff), n_plots, \"mnist_gaussian_diff\")\n",
    "      plot_images(gen_images, n_plots, \"mnist_generated\", classified_generated_images)\n",
    "      plot_images(torch.abs(gen_diff), n_plots, \"mnist_generated_diff\")\n",
    "\n",
    "      print(\"Discriminator 2 guess on input images (real)\\n\", classified_input_images[:5])\n",
    "      print(\"Discriminator 2 guess on generated images (fake)\\n\", classified_generated_images[:5].unsqueeze(-1).transpose(0,1))\n",
    "      print(\"Discriminator 2 guess on noisy images (fake)\\n\", classified_noisy_images[:5].unsqueeze(-1).transpose(0,1))\n",
    "\n",
    "\n",
    "    #break  # Remove this line to process the entire dataset\n",
    "\n",
    "\n",
    "print(\"Input images accuracy\\n\", input_images_matches / len(test_loader.dataset)) #/input_images.size(0))\n",
    "print(\"Generated images accuracy\\n\", generated_images_matches / len(test_loader.dataset)) #/input_images.size(0))\n",
    "print(\"Noisy images accuracy\\n\", noisy_images_matches / len(test_loader.dataset)) #/input_images.size(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AB9LkZIZo-Jr"
   },
   "outputs": [],
   "source": [
    "def generate_ssims(gan, strength_factor=1):\n",
    "    gen_image_ssims = []\n",
    "    noisy_image_ssims = []\n",
    "    ssim = StructuralSimilarityIndexMeasure(reduction=None)\n",
    "\n",
    "    for i_batch, batch in enumerate(test_loader):\n",
    "        input, _ = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gen_output = gan.generator(input.to(device)).cpu()\n",
    "\n",
    "        gen_diff = input - gen_output\n",
    "        gen_norm = torch.norm(gen_diff, dim=(2,3))\n",
    "\n",
    "        noisy_input = generate_gaussian_noise(input, alpha = gen_norm)\n",
    "        gaussian_diff = input_images - noisy_images\n",
    "\n",
    "        gen_image_ssims.append(ssim(gen_output, input))\n",
    "        noisy_image_ssims.append(ssim(noisy_input, input))\n",
    "\n",
    "    gen_image_ssims = torch.concat(gen_image_ssims)\n",
    "    noisy_image_ssims = torch.concat(noisy_image_ssims)\n",
    "\n",
    "    return gen_image_ssims, noisy_image_ssims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_kkvateW3rNN",
    "outputId": "e2bd5476-ebc3-4381-bc90-31d1b8378b20"
   },
   "outputs": [],
   "source": [
    "def plot_ssim_histograms(gen_image_ssims, noisy_image_ssims, plot_name):\n",
    "    # plt.figure(figsize=(5,2))\n",
    "    cm = 1/2.54  # centimeters in inches\n",
    "    plt.figure(figsize=(7*cm, 7*cm))\n",
    "    sns.histplot(gen_image_ssims.detach().cpu().numpy(), stat=\"probability\", bins=30, color=\"darkred\", edgecolor=None, alpha=0.8, label=\"Adversarial noise\")\n",
    "    sns.histplot(noisy_image_ssims.detach().cpu().numpy(), stat=\"probability\", bins=30, color=\"gray\", edgecolor=None, alpha=0.8, label=\"Gaussian noise\")\n",
    "    plt.xlim(0,1)\n",
    "    plt.xlabel(\"SSIM\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"plot_{plot_name}.png\")\n",
    "\n",
    "gen_image_ssims, noisy_image_ssims = generate_ssims(gan)\n",
    "print(torch.mean(gen_image_ssims).item(), torch.mean(noisy_image_ssims).item())\n",
    "plot_ssim_histograms(gen_image_ssims, noisy_image_ssims, \"test_ssim_histogram_adversarial_gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mx1MqEc8SVKq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "0MCMp9tcYbN0",
    "outputId": "20eb904f-a15c-4e32-d9bc-94e81e2587f2"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy_over_strength_factor(gan, n_steps=11):\n",
    "    strength_factors = np.linspace(0, 1, n_steps).tolist()\n",
    "    gen_image_accuracy_results = []\n",
    "    noisy_image_accuracy_results = []\n",
    "    gen_image_ssim_results = []\n",
    "    noisy_image_ssim_results = []\n",
    "\n",
    "    for factor in strength_factors:\n",
    "        input_matches = 0\n",
    "        n_gen_output_matches = 0\n",
    "        n_noisy_input_matches = 0\n",
    "        gen_image_ssims = []\n",
    "        noisy_image_ssims = []\n",
    "        ssim = StructuralSimilarityIndexMeasure(reduction=None)\n",
    "\n",
    "        for i_batch, batch in enumerate(test_loader):\n",
    "            input, labels = batch\n",
    "            factor_tensor = torch.ones_like(input) * factor\n",
    "\n",
    "            with torch.no_grad():\n",
    "                gen_output = gan.generator(input.to(device)).cpu()\n",
    "\n",
    "            gen_diff = gen_output - input\n",
    "            gen_norm = torch.norm(gen_diff, dim=(2, 3))\n",
    "\n",
    "            noisy_input = generate_gaussian_noise(input, alpha=gen_norm)\n",
    "            noisy_diff = noisy_input - input\n",
    "\n",
    "            # Add noise to input images up to a factor\n",
    "            gen_output_factorized = input + factor_tensor * gen_diff\n",
    "            noisy_input_factorized = input + factor_tensor * noisy_diff\n",
    "\n",
    "            gen_image_ssims.append(ssim(gen_output_factorized, input))\n",
    "            noisy_image_ssims.append(ssim(noisy_input_factorized, input))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                classified_gen_output = torch.argmax(gan.discriminator_2((gen_output_factorized).to(device)).cpu(), dim=1)\n",
    "                classified_noisy_input = torch.argmax(gan.discriminator_2((noisy_input_factorized).to(device)).cpu(), dim=1)\n",
    "\n",
    "            n_gen_output_matches += torch.sum(labels == classified_gen_output.unsqueeze(-1))\n",
    "            n_noisy_input_matches += torch.sum(labels == classified_noisy_input.unsqueeze(-1))\n",
    "\n",
    "        gen_image_accuracy_results.append((n_gen_output_matches / len(test_loader.dataset)).item())\n",
    "        noisy_image_accuracy_results.append((n_noisy_input_matches / len(test_loader.dataset)).item())\n",
    "        gen_image_ssim_results.append(torch.concat(gen_image_ssims).mean().item())\n",
    "        noisy_image_ssim_results.append(torch.concat(noisy_image_ssims).mean().item())\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"strength_factor\": strength_factors,\n",
    "            \"gen_image_accuracy\": gen_image_accuracy_results,\n",
    "            \"noisy_image_accuracy\": noisy_image_accuracy_results,\n",
    "            \"gen_image_ssim\": gen_image_ssim_results,\n",
    "            \"noisy_image_ssim\": noisy_image_ssim_results,\n",
    "        }\n",
    "    )\n",
    "\n",
    "accuracy_over_strength_factor_df = calc_accuracy_over_strength_factor(gan, 11)\n",
    "accuracy_over_strength_factor_df.to_csv(\"accuracy_over_strength_factor.csv\", sep=\",\")\n",
    "accuracy_over_strength_factor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "k50U6Cupz1_m",
    "outputId": "982159e6-ed41-4579-e3cf-280ecffdb4f3"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_over_strength_factor(df):\n",
    "    cm = 1/2.54  # centimeters in inches\n",
    "    plt.figure(figsize=(7*cm, 7*cm))\n",
    "    plt.plot(accuracy_over_strength_factor_df[\"strength_factor\"], accuracy_over_strength_factor_df[\"gen_image_accuracy\"], marker=\"o\")\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel(r\"Strength factor, $\\varphi$\")\n",
    "    plt.ylabel(\"Classification accuracy\")\n",
    "    plt.savefig(f\"plot_accuracy_over_strength_factor.png\")\n",
    "\n",
    "plot_accuracy_over_strength_factor(accuracy_over_strength_factor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dX0mrF8lgaG8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_metrics_path = Path(\"/content/drive/MyDrive/data/results/gan_full_logs/version_0/metrics.csv\")\n",
    "training_metrics = pd.read_csv(training_metrics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "CiuphEx30Kth",
    "outputId": "b4fbc355-92af-4850-a4d6-ebfd39747a64"
   },
   "outputs": [],
   "source": [
    "training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_hYAHCpe0ORW",
    "outputId": "e7d61f1a-65e7-4a45-c354-31f7777751d1"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_df):\n",
    "\n",
    "    # Plot generator losses\n",
    "    cm = 1/2.54  # centimeters in inches\n",
    "    plt.figure(figsize=(7*cm, 7*cm))\n",
    "\n",
    "    plt.plot(metrics_df[metrics_df[\"train_gen_loss_disc_1_epoch\"].notnull()][\"epoch\"]+1, metrics_df[\"train_gen_loss_disc_1_epoch\"].dropna(), label=r\"$\\alpha \\mathcal{L}_\\text{Disc. 1}$\", marker=\"o\")\n",
    "    plt.plot(metrics_df[metrics_df[\"train_gen_loss_disc_2_epoch\"].notnull()][\"epoch\"]+1, metrics_df[\"train_gen_loss_disc_2_epoch\"].dropna(), label=r\"$\\beta \\mathcal{L}_\\text{Disc. 2}^*$\", marker=\"o\")\n",
    "    plt.plot(metrics_df[metrics_df[\"train_gen_loss_norm_epoch\"].notnull()][\"epoch\"]+1, metrics_df[\"train_gen_loss_norm_epoch\"].dropna(), label=r\"$\\gamma \\mathcal{L}_\\text{Norm}$\", marker=\"o\")\n",
    "    plt.xlim(min(metrics_df[metrics_df[\"train_gen_loss_disc_1_epoch\"].notnull()][\"epoch\"]+1), max(metrics_df[metrics_df[\"train_gen_loss_disc_1_epoch\"].notnull()][\"epoch\"]+1))\n",
    "    plt.xticks(np.arange(min(metrics_df[metrics_df[\"train_disc_2_loss_epoch\"].notnull()][\"epoch\"]+1), max(metrics_df[metrics_df[\"train_disc_2_loss_epoch\"].notnull()][\"epoch\"]+1)+1, 4))\n",
    "    plt.xlabel(\"Training epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(f\"plot_train_gen_loss_components_epoch.png\")\n",
    "\n",
    "    # Plot discriminator 2 Loss\n",
    "    fig, ax1 = plt.subplots(figsize=(7*cm, 7*cm))\n",
    "    # ax2 = ax1.twiny()\n",
    "\n",
    "    # ax2.plot(metrics_df[metrics_df[\"train_disc_2_loss_step\"].notnull()][\"step\"], metrics_df[\"train_disc_2_loss_step\"].dropna(), alpha=0.5, lw=0.2)\n",
    "    # ax2.set_xlim(min(metrics_df[metrics_df[\"train_gen_loss_step\"].notnull()][\"step\"]), max(metrics_df[metrics_df[\"train_gen_loss_step\"].notnull()][\"step\"]))\n",
    "    # ax2.set_xlabel(\"Training step\")\n",
    "\n",
    "    ax1.plot(metrics_df[metrics_df[\"train_disc_2_loss_epoch\"].notnull()][\"epoch\"]+1, metrics_df[\"train_disc_2_loss_epoch\"].dropna(), marker=\"o\")\n",
    "    ax1.set_xlim(min(metrics_df[metrics_df[\"train_disc_2_loss_epoch\"].notnull()][\"epoch\"]+1), max(metrics_df[metrics_df[\"train_disc_2_loss_epoch\"].notnull()][\"epoch\"]+1))\n",
    "    ax1.set_xticks(np.arange(min(metrics_df[metrics_df[\"train_disc_2_loss_epoch\"].notnull()][\"epoch\"]+1), max(metrics_df[metrics_df[\"train_disc_2_loss_epoch\"].notnull()][\"epoch\"]+1)+1, 4))\n",
    "    ax1.set_xlabel(\"Training epoch\")\n",
    "\n",
    "    plt.ylabel(r\"$\\mathcal{L}_\\text{Disc. 2}$ loss\")\n",
    "    plt.savefig(f\"plot_train_disc_2_loss_epoch.png\")\n",
    "\n",
    "\n",
    "plot_metrics(training_metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
